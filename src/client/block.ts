// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.0
//   protoc               v5.29.3
// source: block.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { AggregateBody } from "./transaction";

export const protobufPackage = "tari.rpc";

/**
 * Copyright 2020. The Tari Project
 *
 * Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
 * following conditions are met:
 *
 * 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following
 * disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the
 * following disclaimer in the documentation and/or other materials provided with the distribution.
 *
 * 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote
 * products derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
 * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

/**
 * The BlockHeader contains all the metadata for the block, including proof of work, a link to the previous block
 * and the transaction kernels.
 */
export interface BlockHeader {
  /** The hash of the block */
  hash: Uint8Array;
  /** Version of the block */
  version: number;
  /** Height of this block since the genesis block (height 0) */
  height: Long;
  /** Hash of the block previous to this in the chain. */
  prevHash: Uint8Array;
  /** Timestamp at which the block was built. */
  timestamp: Long;
  /** This is the UTXO merkle root of the outputs in the blockchain */
  outputMr: Uint8Array;
  /** This is the merkle root of all outputs in this block */
  blockOutputMr: Uint8Array;
  /** This is the MMR root of the kernels */
  kernelMr: Uint8Array;
  /** This is the Merkle root of the inputs in this block */
  inputMr: Uint8Array;
  /**
   * Total accumulated sum of kernel offsets since genesis block. We can derive the kernel offset sum for *this*
   * block from the total kernel offset of the previous block header.
   */
  totalKernelOffset: Uint8Array;
  /** Nonce increment used to mine this block. */
  nonce: Long;
  /** Proof of work metadata */
  pow:
    | ProofOfWork
    | undefined;
  /** Kernel MMR size */
  kernelMmrSize: Long;
  /** Output MMR size */
  outputMmrSize: Long;
  /** Sum of script offsets for all kernels in this block. */
  totalScriptOffset: Uint8Array;
  /** Merkle root of validator nodes */
  validatorNodeMr: Uint8Array;
  /** Validator size */
  validatorNodeSize: Long;
}

/** The proof of work data structure that is included in the block header. */
export interface ProofOfWork {
  /**
   * The algorithm used to mine this block
   *   0 = Monero
   *   1 = Sha3X
   */
  powAlgo: Long;
  /**
   * Supplemental proof of work data. For example for Sha3x, this would be empty (only the block header is
   * required), but for Monero merge mining we need the Monero block header and RandomX seed hash.
   */
  powData: Uint8Array;
}

/** This is used to request the which pow algo should be used with the block template */
export interface PowAlgo {
  /** The pow algo to use */
  powAlgo: PowAlgo_PowAlgos;
}

/** The permitted pow algorithms */
export enum PowAlgo_PowAlgos {
  /** POW_ALGOS_RANDOMX - Accessible as `grpc::pow_algo::PowAlgos::Randomx` */
  POW_ALGOS_RANDOMX = 0,
  /** POW_ALGOS_SHA3X - Accessible as `grpc::pow_algo::PowAlgos::Sha3x` */
  POW_ALGOS_SHA3X = 1,
  UNRECOGNIZED = -1,
}

export function powAlgo_PowAlgosFromJSON(object: any): PowAlgo_PowAlgos {
  switch (object) {
    case 0:
    case "POW_ALGOS_RANDOMX":
      return PowAlgo_PowAlgos.POW_ALGOS_RANDOMX;
    case 1:
    case "POW_ALGOS_SHA3X":
      return PowAlgo_PowAlgos.POW_ALGOS_SHA3X;
    case -1:
    case "UNRECOGNIZED":
    default:
      return PowAlgo_PowAlgos.UNRECOGNIZED;
  }
}

export function powAlgo_PowAlgosToJSON(object: PowAlgo_PowAlgos): string {
  switch (object) {
    case PowAlgo_PowAlgos.POW_ALGOS_RANDOMX:
      return "POW_ALGOS_RANDOMX";
    case PowAlgo_PowAlgos.POW_ALGOS_SHA3X:
      return "POW_ALGOS_SHA3X";
    case PowAlgo_PowAlgos.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A Minotari block. Blocks are linked together into a blockchain. */
export interface Block {
  /**
   * The BlockHeader contains all the metadata for the block, including proof of work, a link to the previous block
   * and the transaction kernels.
   */
  header:
    | BlockHeader
    | undefined;
  /**
   * The components of the block or transaction. The same struct can be used for either, since in Mimblewimble,
   * blocks consist of inputs, outputs and kernels, rather than transactions.
   */
  body: AggregateBody | undefined;
}

/**
 * The representation of a historical block in the blockchain. It is essentially identical to a protocol-defined
 * block but contains some extra metadata that clients such as Block Explorers will find interesting.
 */
export interface HistoricalBlock {
  /**
   * The number of blocks that have been mined since this block, including this one. The current tip will have one
   * confirmation.
   */
  confirmations: Long;
  /** The underlying block */
  block: Block | undefined;
}

/** The NewBlockHeaderTemplate is used for the construction of a new mine-able block. It contains all the metadata for the block that the Base Node is able to complete on behalf of a Miner. */
export interface NewBlockHeaderTemplate {
  /** Version of the block */
  version: number;
  /** Height of this block since the genesis block (height 0) */
  height: Long;
  /** Hash of the block previous to this in the chain. */
  prevHash: Uint8Array;
  /**
   * Total accumulated sum of kernel offsets since genesis block. We can derive the kernel offset sum for *this*
   * block from the total kernel offset of the previous block header.
   */
  totalKernelOffset: Uint8Array;
  /** Proof of work metadata */
  pow:
    | ProofOfWork
    | undefined;
  /** Sum of script offsets for all kernels in this block. */
  totalScriptOffset: Uint8Array;
}

/** The new block template is used constructing a new partial block, allowing a miner to added the coinbase utxo and as a final step the Base node to add the MMR roots to the header. */
export interface NewBlockTemplate {
  /**
   * The NewBlockHeaderTemplate is used for the construction of a new mineable block. It contains all the metadata for
   * the block that the Base Node is able to complete on behalf of a Miner.
   */
  header:
    | NewBlockHeaderTemplate
    | undefined;
  /**
   * This flag indicates if the inputs, outputs and kernels have been sorted internally, that is, the sort() method
   * has been called. This may be false even if all components are sorted.
   */
  body:
    | AggregateBody
    | undefined;
  /**
   * Sometimes the mempool has not synced to the latest tip, this flag indicates if the mempool is out of sync.
   * In most cases the next call to get_new_block_template will return a block with the mempool in sync.
   */
  isMempoolInSync: boolean;
}

function createBaseBlockHeader(): BlockHeader {
  return {
    hash: new Uint8Array(0),
    version: 0,
    height: Long.UZERO,
    prevHash: new Uint8Array(0),
    timestamp: Long.UZERO,
    outputMr: new Uint8Array(0),
    blockOutputMr: new Uint8Array(0),
    kernelMr: new Uint8Array(0),
    inputMr: new Uint8Array(0),
    totalKernelOffset: new Uint8Array(0),
    nonce: Long.UZERO,
    pow: undefined,
    kernelMmrSize: Long.UZERO,
    outputMmrSize: Long.UZERO,
    totalScriptOffset: new Uint8Array(0),
    validatorNodeMr: new Uint8Array(0),
    validatorNodeSize: Long.UZERO,
  };
}

export const BlockHeader: MessageFns<BlockHeader> = {
  encode(message: BlockHeader, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hash.length !== 0) {
      writer.uint32(10).bytes(message.hash);
    }
    if (message.version !== 0) {
      writer.uint32(16).uint32(message.version);
    }
    if (!message.height.equals(Long.UZERO)) {
      writer.uint32(24).uint64(message.height.toString());
    }
    if (message.prevHash.length !== 0) {
      writer.uint32(34).bytes(message.prevHash);
    }
    if (!message.timestamp.equals(Long.UZERO)) {
      writer.uint32(40).uint64(message.timestamp.toString());
    }
    if (message.outputMr.length !== 0) {
      writer.uint32(50).bytes(message.outputMr);
    }
    if (message.blockOutputMr.length !== 0) {
      writer.uint32(58).bytes(message.blockOutputMr);
    }
    if (message.kernelMr.length !== 0) {
      writer.uint32(66).bytes(message.kernelMr);
    }
    if (message.inputMr.length !== 0) {
      writer.uint32(74).bytes(message.inputMr);
    }
    if (message.totalKernelOffset.length !== 0) {
      writer.uint32(82).bytes(message.totalKernelOffset);
    }
    if (!message.nonce.equals(Long.UZERO)) {
      writer.uint32(88).uint64(message.nonce.toString());
    }
    if (message.pow !== undefined) {
      ProofOfWork.encode(message.pow, writer.uint32(98).fork()).join();
    }
    if (!message.kernelMmrSize.equals(Long.UZERO)) {
      writer.uint32(104).uint64(message.kernelMmrSize.toString());
    }
    if (!message.outputMmrSize.equals(Long.UZERO)) {
      writer.uint32(112).uint64(message.outputMmrSize.toString());
    }
    if (message.totalScriptOffset.length !== 0) {
      writer.uint32(122).bytes(message.totalScriptOffset);
    }
    if (message.validatorNodeMr.length !== 0) {
      writer.uint32(130).bytes(message.validatorNodeMr);
    }
    if (!message.validatorNodeSize.equals(Long.UZERO)) {
      writer.uint32(136).uint64(message.validatorNodeSize.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BlockHeader {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBlockHeader();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.hash = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.version = reader.uint32();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.height = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.prevHash = reader.bytes();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.timestamp = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.outputMr = reader.bytes();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.blockOutputMr = reader.bytes();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.kernelMr = reader.bytes();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.inputMr = reader.bytes();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.totalKernelOffset = reader.bytes();
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.nonce = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.pow = ProofOfWork.decode(reader, reader.uint32());
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.kernelMmrSize = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 14: {
          if (tag !== 112) {
            break;
          }

          message.outputMmrSize = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.totalScriptOffset = reader.bytes();
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.validatorNodeMr = reader.bytes();
          continue;
        }
        case 17: {
          if (tag !== 136) {
            break;
          }

          message.validatorNodeSize = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BlockHeader {
    return {
      hash: isSet(object.hash) ? bytesFromBase64(object.hash) : new Uint8Array(0),
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
      height: isSet(object.height) ? Long.fromValue(object.height) : Long.UZERO,
      prevHash: isSet(object.prevHash) ? bytesFromBase64(object.prevHash) : new Uint8Array(0),
      timestamp: isSet(object.timestamp) ? Long.fromValue(object.timestamp) : Long.UZERO,
      outputMr: isSet(object.outputMr) ? bytesFromBase64(object.outputMr) : new Uint8Array(0),
      blockOutputMr: isSet(object.blockOutputMr) ? bytesFromBase64(object.blockOutputMr) : new Uint8Array(0),
      kernelMr: isSet(object.kernelMr) ? bytesFromBase64(object.kernelMr) : new Uint8Array(0),
      inputMr: isSet(object.inputMr) ? bytesFromBase64(object.inputMr) : new Uint8Array(0),
      totalKernelOffset: isSet(object.totalKernelOffset)
        ? bytesFromBase64(object.totalKernelOffset)
        : new Uint8Array(0),
      nonce: isSet(object.nonce) ? Long.fromValue(object.nonce) : Long.UZERO,
      pow: isSet(object.pow) ? ProofOfWork.fromJSON(object.pow) : undefined,
      kernelMmrSize: isSet(object.kernelMmrSize) ? Long.fromValue(object.kernelMmrSize) : Long.UZERO,
      outputMmrSize: isSet(object.outputMmrSize) ? Long.fromValue(object.outputMmrSize) : Long.UZERO,
      totalScriptOffset: isSet(object.totalScriptOffset)
        ? bytesFromBase64(object.totalScriptOffset)
        : new Uint8Array(0),
      validatorNodeMr: isSet(object.validatorNodeMr) ? bytesFromBase64(object.validatorNodeMr) : new Uint8Array(0),
      validatorNodeSize: isSet(object.validatorNodeSize) ? Long.fromValue(object.validatorNodeSize) : Long.UZERO,
    };
  },

  toJSON(message: BlockHeader): unknown {
    const obj: any = {};
    if (message.hash.length !== 0) {
      obj.hash = base64FromBytes(message.hash);
    }
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    if (!message.height.equals(Long.UZERO)) {
      obj.height = (message.height || Long.UZERO).toString();
    }
    if (message.prevHash.length !== 0) {
      obj.prevHash = base64FromBytes(message.prevHash);
    }
    if (!message.timestamp.equals(Long.UZERO)) {
      obj.timestamp = (message.timestamp || Long.UZERO).toString();
    }
    if (message.outputMr.length !== 0) {
      obj.outputMr = base64FromBytes(message.outputMr);
    }
    if (message.blockOutputMr.length !== 0) {
      obj.blockOutputMr = base64FromBytes(message.blockOutputMr);
    }
    if (message.kernelMr.length !== 0) {
      obj.kernelMr = base64FromBytes(message.kernelMr);
    }
    if (message.inputMr.length !== 0) {
      obj.inputMr = base64FromBytes(message.inputMr);
    }
    if (message.totalKernelOffset.length !== 0) {
      obj.totalKernelOffset = base64FromBytes(message.totalKernelOffset);
    }
    if (!message.nonce.equals(Long.UZERO)) {
      obj.nonce = (message.nonce || Long.UZERO).toString();
    }
    if (message.pow !== undefined) {
      obj.pow = ProofOfWork.toJSON(message.pow);
    }
    if (!message.kernelMmrSize.equals(Long.UZERO)) {
      obj.kernelMmrSize = (message.kernelMmrSize || Long.UZERO).toString();
    }
    if (!message.outputMmrSize.equals(Long.UZERO)) {
      obj.outputMmrSize = (message.outputMmrSize || Long.UZERO).toString();
    }
    if (message.totalScriptOffset.length !== 0) {
      obj.totalScriptOffset = base64FromBytes(message.totalScriptOffset);
    }
    if (message.validatorNodeMr.length !== 0) {
      obj.validatorNodeMr = base64FromBytes(message.validatorNodeMr);
    }
    if (!message.validatorNodeSize.equals(Long.UZERO)) {
      obj.validatorNodeSize = (message.validatorNodeSize || Long.UZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BlockHeader>, I>>(base?: I): BlockHeader {
    return BlockHeader.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BlockHeader>, I>>(object: I): BlockHeader {
    const message = createBaseBlockHeader();
    message.hash = object.hash ?? new Uint8Array(0);
    message.version = object.version ?? 0;
    message.height = (object.height !== undefined && object.height !== null)
      ? Long.fromValue(object.height)
      : Long.UZERO;
    message.prevHash = object.prevHash ?? new Uint8Array(0);
    message.timestamp = (object.timestamp !== undefined && object.timestamp !== null)
      ? Long.fromValue(object.timestamp)
      : Long.UZERO;
    message.outputMr = object.outputMr ?? new Uint8Array(0);
    message.blockOutputMr = object.blockOutputMr ?? new Uint8Array(0);
    message.kernelMr = object.kernelMr ?? new Uint8Array(0);
    message.inputMr = object.inputMr ?? new Uint8Array(0);
    message.totalKernelOffset = object.totalKernelOffset ?? new Uint8Array(0);
    message.nonce = (object.nonce !== undefined && object.nonce !== null) ? Long.fromValue(object.nonce) : Long.UZERO;
    message.pow = (object.pow !== undefined && object.pow !== null) ? ProofOfWork.fromPartial(object.pow) : undefined;
    message.kernelMmrSize = (object.kernelMmrSize !== undefined && object.kernelMmrSize !== null)
      ? Long.fromValue(object.kernelMmrSize)
      : Long.UZERO;
    message.outputMmrSize = (object.outputMmrSize !== undefined && object.outputMmrSize !== null)
      ? Long.fromValue(object.outputMmrSize)
      : Long.UZERO;
    message.totalScriptOffset = object.totalScriptOffset ?? new Uint8Array(0);
    message.validatorNodeMr = object.validatorNodeMr ?? new Uint8Array(0);
    message.validatorNodeSize = (object.validatorNodeSize !== undefined && object.validatorNodeSize !== null)
      ? Long.fromValue(object.validatorNodeSize)
      : Long.UZERO;
    return message;
  },
};

function createBaseProofOfWork(): ProofOfWork {
  return { powAlgo: Long.UZERO, powData: new Uint8Array(0) };
}

export const ProofOfWork: MessageFns<ProofOfWork> = {
  encode(message: ProofOfWork, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.powAlgo.equals(Long.UZERO)) {
      writer.uint32(8).uint64(message.powAlgo.toString());
    }
    if (message.powData.length !== 0) {
      writer.uint32(34).bytes(message.powData);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ProofOfWork {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProofOfWork();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.powAlgo = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.powData = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProofOfWork {
    return {
      powAlgo: isSet(object.powAlgo) ? Long.fromValue(object.powAlgo) : Long.UZERO,
      powData: isSet(object.powData) ? bytesFromBase64(object.powData) : new Uint8Array(0),
    };
  },

  toJSON(message: ProofOfWork): unknown {
    const obj: any = {};
    if (!message.powAlgo.equals(Long.UZERO)) {
      obj.powAlgo = (message.powAlgo || Long.UZERO).toString();
    }
    if (message.powData.length !== 0) {
      obj.powData = base64FromBytes(message.powData);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ProofOfWork>, I>>(base?: I): ProofOfWork {
    return ProofOfWork.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ProofOfWork>, I>>(object: I): ProofOfWork {
    const message = createBaseProofOfWork();
    message.powAlgo = (object.powAlgo !== undefined && object.powAlgo !== null)
      ? Long.fromValue(object.powAlgo)
      : Long.UZERO;
    message.powData = object.powData ?? new Uint8Array(0);
    return message;
  },
};

function createBasePowAlgo(): PowAlgo {
  return { powAlgo: 0 };
}

export const PowAlgo: MessageFns<PowAlgo> = {
  encode(message: PowAlgo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.powAlgo !== 0) {
      writer.uint32(8).int32(message.powAlgo);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PowAlgo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePowAlgo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.powAlgo = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PowAlgo {
    return { powAlgo: isSet(object.powAlgo) ? powAlgo_PowAlgosFromJSON(object.powAlgo) : 0 };
  },

  toJSON(message: PowAlgo): unknown {
    const obj: any = {};
    if (message.powAlgo !== 0) {
      obj.powAlgo = powAlgo_PowAlgosToJSON(message.powAlgo);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PowAlgo>, I>>(base?: I): PowAlgo {
    return PowAlgo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PowAlgo>, I>>(object: I): PowAlgo {
    const message = createBasePowAlgo();
    message.powAlgo = object.powAlgo ?? 0;
    return message;
  },
};

function createBaseBlock(): Block {
  return { header: undefined, body: undefined };
}

export const Block: MessageFns<Block> = {
  encode(message: Block, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.header !== undefined) {
      BlockHeader.encode(message.header, writer.uint32(10).fork()).join();
    }
    if (message.body !== undefined) {
      AggregateBody.encode(message.body, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Block {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBlock();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.header = BlockHeader.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.body = AggregateBody.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Block {
    return {
      header: isSet(object.header) ? BlockHeader.fromJSON(object.header) : undefined,
      body: isSet(object.body) ? AggregateBody.fromJSON(object.body) : undefined,
    };
  },

  toJSON(message: Block): unknown {
    const obj: any = {};
    if (message.header !== undefined) {
      obj.header = BlockHeader.toJSON(message.header);
    }
    if (message.body !== undefined) {
      obj.body = AggregateBody.toJSON(message.body);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Block>, I>>(base?: I): Block {
    return Block.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Block>, I>>(object: I): Block {
    const message = createBaseBlock();
    message.header = (object.header !== undefined && object.header !== null)
      ? BlockHeader.fromPartial(object.header)
      : undefined;
    message.body = (object.body !== undefined && object.body !== null)
      ? AggregateBody.fromPartial(object.body)
      : undefined;
    return message;
  },
};

function createBaseHistoricalBlock(): HistoricalBlock {
  return { confirmations: Long.UZERO, block: undefined };
}

export const HistoricalBlock: MessageFns<HistoricalBlock> = {
  encode(message: HistoricalBlock, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.confirmations.equals(Long.UZERO)) {
      writer.uint32(8).uint64(message.confirmations.toString());
    }
    if (message.block !== undefined) {
      Block.encode(message.block, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HistoricalBlock {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHistoricalBlock();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.confirmations = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.block = Block.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HistoricalBlock {
    return {
      confirmations: isSet(object.confirmations) ? Long.fromValue(object.confirmations) : Long.UZERO,
      block: isSet(object.block) ? Block.fromJSON(object.block) : undefined,
    };
  },

  toJSON(message: HistoricalBlock): unknown {
    const obj: any = {};
    if (!message.confirmations.equals(Long.UZERO)) {
      obj.confirmations = (message.confirmations || Long.UZERO).toString();
    }
    if (message.block !== undefined) {
      obj.block = Block.toJSON(message.block);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<HistoricalBlock>, I>>(base?: I): HistoricalBlock {
    return HistoricalBlock.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<HistoricalBlock>, I>>(object: I): HistoricalBlock {
    const message = createBaseHistoricalBlock();
    message.confirmations = (object.confirmations !== undefined && object.confirmations !== null)
      ? Long.fromValue(object.confirmations)
      : Long.UZERO;
    message.block = (object.block !== undefined && object.block !== null) ? Block.fromPartial(object.block) : undefined;
    return message;
  },
};

function createBaseNewBlockHeaderTemplate(): NewBlockHeaderTemplate {
  return {
    version: 0,
    height: Long.UZERO,
    prevHash: new Uint8Array(0),
    totalKernelOffset: new Uint8Array(0),
    pow: undefined,
    totalScriptOffset: new Uint8Array(0),
  };
}

export const NewBlockHeaderTemplate: MessageFns<NewBlockHeaderTemplate> = {
  encode(message: NewBlockHeaderTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== 0) {
      writer.uint32(8).uint32(message.version);
    }
    if (!message.height.equals(Long.UZERO)) {
      writer.uint32(16).uint64(message.height.toString());
    }
    if (message.prevHash.length !== 0) {
      writer.uint32(26).bytes(message.prevHash);
    }
    if (message.totalKernelOffset.length !== 0) {
      writer.uint32(34).bytes(message.totalKernelOffset);
    }
    if (message.pow !== undefined) {
      ProofOfWork.encode(message.pow, writer.uint32(42).fork()).join();
    }
    if (message.totalScriptOffset.length !== 0) {
      writer.uint32(58).bytes(message.totalScriptOffset);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NewBlockHeaderTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNewBlockHeaderTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.version = reader.uint32();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.height = Long.fromString(reader.uint64().toString(), true);
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.prevHash = reader.bytes();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.totalKernelOffset = reader.bytes();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.pow = ProofOfWork.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.totalScriptOffset = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NewBlockHeaderTemplate {
    return {
      version: isSet(object.version) ? globalThis.Number(object.version) : 0,
      height: isSet(object.height) ? Long.fromValue(object.height) : Long.UZERO,
      prevHash: isSet(object.prevHash) ? bytesFromBase64(object.prevHash) : new Uint8Array(0),
      totalKernelOffset: isSet(object.totalKernelOffset)
        ? bytesFromBase64(object.totalKernelOffset)
        : new Uint8Array(0),
      pow: isSet(object.pow) ? ProofOfWork.fromJSON(object.pow) : undefined,
      totalScriptOffset: isSet(object.totalScriptOffset)
        ? bytesFromBase64(object.totalScriptOffset)
        : new Uint8Array(0),
    };
  },

  toJSON(message: NewBlockHeaderTemplate): unknown {
    const obj: any = {};
    if (message.version !== 0) {
      obj.version = Math.round(message.version);
    }
    if (!message.height.equals(Long.UZERO)) {
      obj.height = (message.height || Long.UZERO).toString();
    }
    if (message.prevHash.length !== 0) {
      obj.prevHash = base64FromBytes(message.prevHash);
    }
    if (message.totalKernelOffset.length !== 0) {
      obj.totalKernelOffset = base64FromBytes(message.totalKernelOffset);
    }
    if (message.pow !== undefined) {
      obj.pow = ProofOfWork.toJSON(message.pow);
    }
    if (message.totalScriptOffset.length !== 0) {
      obj.totalScriptOffset = base64FromBytes(message.totalScriptOffset);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NewBlockHeaderTemplate>, I>>(base?: I): NewBlockHeaderTemplate {
    return NewBlockHeaderTemplate.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NewBlockHeaderTemplate>, I>>(object: I): NewBlockHeaderTemplate {
    const message = createBaseNewBlockHeaderTemplate();
    message.version = object.version ?? 0;
    message.height = (object.height !== undefined && object.height !== null)
      ? Long.fromValue(object.height)
      : Long.UZERO;
    message.prevHash = object.prevHash ?? new Uint8Array(0);
    message.totalKernelOffset = object.totalKernelOffset ?? new Uint8Array(0);
    message.pow = (object.pow !== undefined && object.pow !== null) ? ProofOfWork.fromPartial(object.pow) : undefined;
    message.totalScriptOffset = object.totalScriptOffset ?? new Uint8Array(0);
    return message;
  },
};

function createBaseNewBlockTemplate(): NewBlockTemplate {
  return { header: undefined, body: undefined, isMempoolInSync: false };
}

export const NewBlockTemplate: MessageFns<NewBlockTemplate> = {
  encode(message: NewBlockTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.header !== undefined) {
      NewBlockHeaderTemplate.encode(message.header, writer.uint32(10).fork()).join();
    }
    if (message.body !== undefined) {
      AggregateBody.encode(message.body, writer.uint32(18).fork()).join();
    }
    if (message.isMempoolInSync !== false) {
      writer.uint32(24).bool(message.isMempoolInSync);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NewBlockTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNewBlockTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.header = NewBlockHeaderTemplate.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.body = AggregateBody.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.isMempoolInSync = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NewBlockTemplate {
    return {
      header: isSet(object.header) ? NewBlockHeaderTemplate.fromJSON(object.header) : undefined,
      body: isSet(object.body) ? AggregateBody.fromJSON(object.body) : undefined,
      isMempoolInSync: isSet(object.isMempoolInSync) ? globalThis.Boolean(object.isMempoolInSync) : false,
    };
  },

  toJSON(message: NewBlockTemplate): unknown {
    const obj: any = {};
    if (message.header !== undefined) {
      obj.header = NewBlockHeaderTemplate.toJSON(message.header);
    }
    if (message.body !== undefined) {
      obj.body = AggregateBody.toJSON(message.body);
    }
    if (message.isMempoolInSync !== false) {
      obj.isMempoolInSync = message.isMempoolInSync;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NewBlockTemplate>, I>>(base?: I): NewBlockTemplate {
    return NewBlockTemplate.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NewBlockTemplate>, I>>(object: I): NewBlockTemplate {
    const message = createBaseNewBlockTemplate();
    message.header = (object.header !== undefined && object.header !== null)
      ? NewBlockHeaderTemplate.fromPartial(object.header)
      : undefined;
    message.body = (object.body !== undefined && object.body !== null)
      ? AggregateBody.fromPartial(object.body)
      : undefined;
    message.isMempoolInSync = object.isMempoolInSync ?? false;
    return message;
  },
};

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
